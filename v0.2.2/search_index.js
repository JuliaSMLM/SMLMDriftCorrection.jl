var documenterSearchIndex = {"docs":
[{"location":"api/#API-Reference","page":"API","title":"API Reference","text":"Pages = [\"api.md\", \"configuration.md\"]","category":"section"},{"location":"api/#Main-Interface","page":"API","title":"Main Interface","text":"See Configuration for full documentation of DriftConfig and DriftInfo.","category":"section"},{"location":"api/#SMLD-Alignment","page":"API","title":"SMLD Alignment","text":"See Configuration for full documentation of AlignConfig and AlignInfo.","category":"section"},{"location":"api/#Utility-Functions","page":"API","title":"Utility Functions","text":"","category":"section"},{"location":"api/#Drift-Models","page":"API","title":"Drift Models","text":"","category":"section"},{"location":"api/#Drift-Application","page":"API","title":"Drift Application","text":"","category":"section"},{"location":"api/#Entropy-Functions","page":"API","title":"Entropy Functions","text":"","category":"section"},{"location":"api/#Cross-Correlation","page":"API","title":"Cross-Correlation","text":"","category":"section"},{"location":"api/#SMLMDriftCorrection.driftcorrect","page":"API","title":"SMLMDriftCorrection.driftcorrect","text":"driftcorrect(smld; kwargs...) -> (corrected_smld, info)\ndriftcorrect(smld, config::DriftConfig) -> (corrected_smld, info)\n\nMain interface for drift correction. Uses Legendre polynomial model with entropy-based cost function and adaptive KDTree neighbor building.\n\nArguments\n\nsmld: SMLD structure containing (X, Y) or (X, Y, Z) localization coordinates (μm)\nconfig: Optional DriftConfig struct (alternative to keyword arguments)\n\nKeyword Arguments\n\nquality=:singlepass: Quality tier (:fft, :singlepass, :iterative)\ndegree=2: Polynomial degree for intra-dataset drift model\ndataset_mode=:registered: Semantic label for multi-dataset handling:\n:registered: datasets are independent acquisitions\n:continuous: one long acquisition split into files\nchunk_frames=0: For continuous mode, split each dataset into chunks of this many frames\nn_chunks=0: Alternative to chunk_frames - specify number of chunks per dataset\nmaxn=200: Maximum number of neighbors for entropy calculation\nmax_iterations=10: Maximum iterations for :iterative mode\nconvergence_tol=0.001: Convergence tolerance (μm) for :iterative mode\nwarm_start=nothing: Previous model for warm starting optimization\nverbose=0: Verbosity level (0=quiet, 1=info, 2=debug)\nauto_roi=false: Set to true for faster (but slightly less accurate) estimation using a dense ROI subset\nσ_loc=0.010: Typical localization precision (μm) for ROI sizing\nσ_target=0.001: Target drift precision (μm) for ROI sizing\nroi_safety_factor=4.0: Safety multiplier for required localizations\n\nQuality Tiers\n\n:fft: Fast cross-correlation only (~10x faster, less accurate)\n:singlepass: Current algorithm - parallel intra, then sequential inter (default)\n:iterative: Full convergence - iterates intra↔inter until shift changes < tol\n\nReturns\n\nTuple (corrected_smld, info) where info::DriftInfo contains:\n\nmodel: Fitted drift model (LegendrePolynomial)\nelapsed_s: Wall time in seconds\nbackend: Computation backend (:cpu)\niterations: Number of iterations completed\nconverged: Whether convergence was achieved\nentropy: Final entropy value\nhistory: Entropy per iteration (for diagnostics)\n\nExample\n\n# Basic usage\n(smld_corrected, info) = driftcorrect(smld)\n\n# Using DriftConfig\nconfig = DriftConfig(; quality=:iterative, degree=3, verbose=1)\n(smld_corrected, info) = driftcorrect(smld, config)\n\n# Fast FFT-only mode\n(smld_corrected, info) = driftcorrect(smld; quality=:fft)\n\n# Warm start from previous result\n(smld1, info1) = driftcorrect(smld1; degree=2)\n(smld2, info2) = driftcorrect(smld2; warm_start=info1.model)\n\n# Extract drift trajectory for plotting\ntraj = drift_trajectory(info.model)\n\n\n\n\n\ndriftcorrect(smld, info::DriftInfo; kwargs...) -> (corrected_smld, info)\n\nContinue drift correction from a previous result using the model from info.\n\nKeyword Arguments\n\ndataset_mode=:registered: Dataset mode (:registered or :continuous)\nmax_iterations=10: Additional iterations to run\nconvergence_tol=0.001: Convergence tolerance (μm)\nmaxn=200: Maximum neighbors for entropy calculation\nverbose=0: Verbosity level\n\n\n\n\n\n","category":"function"},{"location":"api/#SMLMDriftCorrection.align_smld","page":"API","title":"SMLMDriftCorrection.align_smld","text":"align_smld(smlds; kwargs...) -> (Vector{<:SMLD}, AlignInfo)\nalign_smld(smlds, config::AlignConfig) -> (Vector{<:SMLD}, AlignInfo)\n\nAlign a vector of independent SMLD structures to a common reference (the first) using rigid shifts. Each SMLD is assumed to be an independent acquisition of the same FOV/structure.\n\nArguments\n\nsmlds: Vector of SMLD structures (>= 2 required)\n\nKeyword Arguments\n\nmethod=:entropy: :entropy (CC initial guess + entropy refinement) or :fft (CC only)\nmaxn=100: Maximum neighbors for entropy calculation\nhistbinsize=0.05: Histogram bin size (μm) for cross-correlation\nverbose=0: Verbosity: 0=quiet, 1=info\n\nReturns\n\nTuple (aligned_smlds, info::AlignInfo) where:\n\naligned_smlds: Vector of aligned SMLDs (first is unchanged)\ninfo.shifts[i]: shift applied to smlds[i] (shifts[1] = zeros)\n\nExample\n\n(aligned, info) = align_smld(smlds)\ninfo.shifts  # [zeros(2), [dx2, dy2], [dx3, dy3], ...]\n\n\n\n\n\n","category":"function"},{"location":"api/#SMLMDriftCorrection.filter_emitters","page":"API","title":"SMLMDriftCorrection.filter_emitters","text":"filter_emitters(smld, keep) -> smld\n\nSelect the emitters indexed by keep from the SMLD structure, returning a new SMLD with only those emitters. keep may be a single positive integer, a range, a vector of integers, or a BitVector mask.\n\nExample\n\nsmld_sub = filter_emitters(smld, [1])\nlength(smld_sub.emitters)  # 1\n\n\n\n\n\n","category":"function"},{"location":"api/#SMLMDriftCorrection.drift_trajectory","page":"API","title":"SMLMDriftCorrection.drift_trajectory","text":"drift_trajectory(model; dataset=nothing, frames=nothing, cumulative=false)\n\nExtract drift trajectory from a drift model for plotting.\n\nArguments\n\nmodel: Polynomial or LegendrePolynomial drift model\ndataset: specific dataset to extract (default: all datasets)\nframes: frame range to evaluate (default: 1:n_frames for each dataset)\ncumulative: if true, chain datasets end-to-end showing total accumulated drift. Useful for registered acquisitions where you want to visualize what drift would look like without stage registration. Default: false.\n\nReturns\n\nNamedTuple with fields ready for plotting:\n\nframes: frame numbers (global if multiple datasets)\nx: x-drift values (μm)\ny: y-drift values (μm)\nz: z-drift values (μm) - only present for 3D models\ndataset: dataset index for each point (useful for coloring)\n\nExample\n\nresult = driftcorrect(smld; dataset_mode=:registered)\ntraj = drift_trajectory(result.model)  # Each dataset relative to ds1\n\n# Cumulative view - chains datasets end-to-end\ntraj_cumul = drift_trajectory(result.model; cumulative=true)\nplot(traj_cumul.frames, traj_cumul.x, label=\"X drift (cumulative)\")\n\n\n\n\n\n","category":"function"},{"location":"api/#SMLMDriftCorrection.LegendrePolynomial","page":"API","title":"SMLMDriftCorrection.LegendrePolynomial","text":"LegendrePolynomial\n\nCombined intra + inter Legendre drift model. Contains one IntraLegendre per dataset plus inter-dataset shifts. The n_frames field stores the valid frame range for drift evaluation.\n\n\n\n\n\n","category":"type"},{"location":"api/#SMLMDriftCorrection.IntraLegendre","page":"API","title":"SMLMDriftCorrection.IntraLegendre","text":"IntraLegendre\n\nIntra-dataset Legendre drift model - wraps one LegendrePoly1D per spatial dimension.\n\n\n\n\n\n","category":"type"},{"location":"api/#SMLMDriftCorrection.LegendrePoly1D","page":"API","title":"SMLMDriftCorrection.LegendrePoly1D","text":"LegendrePoly1D\n\nUnivariate Legendre polynomial drift model for a single spatial dimension. Coefficients are for P1(t), P2(t), ..., P_degree(t) where t is normalized to [-1, 1].\n\nNote: P_0 (constant) is NOT included because the inter-dataset shift already handles global offsets. This matches the convention for standard Polynomial1D which uses t^1, t^2, ... (no constant term).\n\nThe key advantage over standard polynomials: orthogonal basis functions mean each coefficient captures independent variation, leading to better-conditioned optimization.\n\n\n\n\n\n","category":"type"},{"location":"api/#SMLMDriftCorrection.applydrift","page":"API","title":"SMLMDriftCorrection.applydrift","text":"Apply drift to coordinate using Legendre polynomial model. Uses P1 through Pdegree (no constant P_0 term).\n\n\n\n\n\nApply drift to simulated data.\n\n\n\n\n\napplydrift(smld, driftmodel) -> smld\n\nApplies a drift model to SMLM data (for simulation/testing).\n\n\n\n\n\n","category":"function"},{"location":"api/#SMLMDriftCorrection.correctdrift","page":"API","title":"SMLMDriftCorrection.correctdrift","text":"Correct drift from coordinate using Legendre polynomial model. Uses P1 through Pdegree (no constant P_0 term).\n\n\n\n\n\nApply drift correction to drifted data.\n\n\n\n\n\n","category":"function"},{"location":"api/#SMLMDriftCorrection.entropy_HD","page":"API","title":"SMLMDriftCorrection.entropy_HD","text":"H_i(D) is the entropy of the distribution p(r), where D = {d(1),...,d(L)} is the drift at all frames (1 to L). The quantity below is Gaussian Mixture Model single components summed over all localizations provided.\n\nσx and σy are localization uncertainties.\n\n\n\n\n\n","category":"function"},{"location":"api/#SMLMDriftCorrection.ub_entropy","page":"API","title":"SMLMDriftCorrection.ub_entropy","text":"Entropy upper bound based on maxn nearest neighbors of each localization (2D).\n\nArguments\n\nx, y: Vectors of localization positions\nσx, σy: Vectors of localization uncertainties\nmaxn: Maximum number of neighbors considered (default 200)\ndivmethod: Divergence method (\"KL\", \"Symmetric\", \"Bhattacharyya\", \"Mahalanobis\")\n\n\n\n\n\nEntropy upper bound based on maxn nearest neighbors of each localization (3D).\n\n\n\n\n\nMatrix interface for ub_entropy - extracts vectors and calls optimized version. Expects r and σ to be N×K matrices (points as rows, dimensions as columns).\n\n\n\n\n\n","category":"function"},{"location":"api/#SMLMDriftCorrection.findshift","page":"API","title":"SMLMDriftCorrection.findshift","text":"Perform a cross-correlation between images representing localizations in two SMLD structures and compute the shift between the two original images. histbinsize is the size of the bins in the histogram image in the same units as the localization coordinates.\n\n\n\n\n\n","category":"function"},{"location":"api/#SMLMDriftCorrection.histimage2D","page":"API","title":"SMLMDriftCorrection.histimage2D","text":"Produce a histogram image from the localization coordinates x and y. x and y are in arbitrary units. ROI is [xmin, xmax, ymin, ymax] of the Region Of Interest in the same units as x and y.  If not provided, these values are estimated from the coordinate data. histbinsize is the size of the bins of each coordinate in the same units.\n\n\n\n\n\n","category":"function"},{"location":"api/#SMLMDriftCorrection.crosscorr2D","page":"API","title":"SMLMDriftCorrection.crosscorr2D","text":"Compute the cross-correlation between two 2D images with zero-padding.\n\nZero-padding to 2x size eliminates cyclic wrap-around artifacts that cause false peaks at large shifts.\n\n\n\n\n\n","category":"function"},{"location":"configuration/#Configuration","page":"Configuration","title":"Configuration","text":"The primary interface follows the JuliaSMLM tuple pattern:\n\n(smld_corrected, info) = driftcorrect(smld, config)\n\nwhere config is a DriftConfig and info is a DriftInfo.","category":"section"},{"location":"configuration/#Input:-DriftConfig","page":"Configuration","title":"Input: DriftConfig","text":"","category":"section"},{"location":"configuration/#Quality-Tiers","page":"Configuration","title":"Quality Tiers","text":"The quality parameter selects the algorithm complexity:\n\n:fft – Fast cross-correlation of histogram images. No intra-dataset correction. Best for quick previews or very large datasets.\n:singlepass (default) – One pass of entropy-based intra-dataset correction followed by inter-dataset alignment. Good balance of speed and accuracy.\n:iterative – Iterates intra and inter correction until convergence. Most accurate; resolves the coupling between intra and inter drift estimates.","category":"section"},{"location":"configuration/#Dataset-Modes","page":"Configuration","title":"Dataset Modes","text":"The dataset_mode parameter controls how multiple datasets are related:\n\n:registered (default) – Datasets are independent acquisitions of the same field of view (e.g., SeqSRM). Inter-dataset alignment finds the best constant shift for each dataset against the others.\n:continuous – One long acquisition split into multiple files or chunks. Polynomials are warm-started from the previous chunk's endpoint, and inter-shifts are regularized to maintain continuity.","category":"section"},{"location":"configuration/#Chunking-(Continuous-Mode)","page":"Configuration","title":"Chunking (Continuous Mode)","text":"For long continuous acquisitions, a single polynomial may not capture complex drift. Use chunk_frames or n_chunks to split each dataset into temporal segments, each modeled independently:\n\n# Split into ~4000-frame chunks\nconfig = DriftConfig(dataset_mode=:continuous, chunk_frames=4000)\n\n# Or specify number of chunks\nconfig = DriftConfig(dataset_mode=:continuous, n_chunks=3)\n\nEach chunk gets its own polynomial. Warm-starting from the previous chunk's endpoint ensures smooth transitions.","category":"section"},{"location":"configuration/#Auto-ROI","page":"Configuration","title":"Auto-ROI","text":"When auto_roi=true, the algorithm selects a dense rectangular subregion of the field of view for drift estimation, then applies the fitted model to all localizations. This can significantly speed up processing for large datasets while trading some accuracy (~1.4 nm vs ~0.5 nm RMSD in testing).\n\nThe ROI size is determined by σ_loc, σ_target, and roi_safety_factor:\n\nconfig = DriftConfig(auto_roi=true, σ_loc=0.010, σ_target=0.001)\n\nThe estimated ROI indices are stored in info.roi_indices.","category":"section"},{"location":"configuration/#Warm-Starting","page":"Configuration","title":"Warm Starting","text":"Pass a previously fitted model to initialize optimization:\n\n# From a previous correction\n(smld1, info1) = driftcorrect(smld1, DriftConfig(degree=2))\n\n# Use as starting point for new data\nconfig2 = DriftConfig(warm_start=info1.model)\n(smld2, info2) = driftcorrect(smld2, config2)","category":"section"},{"location":"configuration/#Output:-DriftInfo","page":"Configuration","title":"Output: DriftInfo","text":"","category":"section"},{"location":"configuration/#Accessing-Results","page":"Configuration","title":"Accessing Results","text":"(smld_corrected, info) = driftcorrect(smld, DriftConfig())\n\n# Diagnostics\ninfo.converged     # true if convergence criterion met\ninfo.entropy       # final entropy value\ninfo.elapsed_s     # wall time in seconds\ninfo.iterations    # iterations completed (0 for :fft, 1 for :singlepass)\ninfo.history       # entropy per iteration (for plotting convergence)\ninfo.roi_indices   # indices used for ROI subset (nothing if auto_roi=false)","category":"section"},{"location":"configuration/#Drift-Trajectory","page":"Configuration","title":"Drift Trajectory","text":"Extract the fitted drift model for plotting:\n\ntraj = drift_trajectory(info.model)\n# traj.frames, traj.x, traj.y (and traj.z for 3D)\n\n# For continuous mode, chain datasets end-to-end\ntraj = drift_trajectory(info.model; cumulative=true)","category":"section"},{"location":"configuration/#Continuation","page":"Configuration","title":"Continuation","text":"Pass DriftInfo directly to continue iterating from a previous result:\n\n(smld1, info1) = driftcorrect(smld, DriftConfig(quality=:singlepass))\n\n# Continue with more iterations\n(smld2, info2) = driftcorrect(smld, info1; max_iterations=5)","category":"section"},{"location":"configuration/#SMLD-Alignment","page":"Configuration","title":"SMLD Alignment","text":"For aligning independent SMLD structures (e.g., multi-color channels or separate acquisitions of the same FOV), use align_smld with AlignConfig.","category":"section"},{"location":"configuration/#Input:-AlignConfig","page":"Configuration","title":"Input: AlignConfig","text":"","category":"section"},{"location":"configuration/#Output:-AlignInfo","page":"Configuration","title":"Output: AlignInfo","text":"","category":"section"},{"location":"configuration/#Usage","page":"Configuration","title":"Usage","text":"# Entropy method (default) -- CC initial guess + entropy refinement\n(aligned, info) = align_smld([smld_ch1, smld_ch2])\ninfo.shifts  # [zeros(2), [dx, dy]]\n\n# FFT method -- cross-correlation only\n(aligned, info) = align_smld(smlds; method=:fft)\n\n# Config struct form\nconfig = AlignConfig(method=:entropy, maxn=100)\n(aligned, info) = align_smld(smlds, config)\n\nThe entropy method regularizes toward the cross-correlation initial guess to prevent optimizer divergence. Works on both 2D and 3D data, threaded across datasets.","category":"section"},{"location":"configuration/#SMLMDriftCorrection.DriftConfig","page":"Configuration","title":"SMLMDriftCorrection.DriftConfig","text":"DriftConfig <: AbstractSMLMConfig\n\nConfiguration for drift correction, holding all algorithm parameters. Constructed with keyword arguments; all fields have sensible defaults.\n\nFields\n\nField Default Description\nquality :singlepass Quality tier: :fft, :singlepass, or :iterative\ndegree 2 Legendre polynomial degree for intra-dataset drift\ndataset_mode :registered Multi-dataset handling: :registered or :continuous\nchunk_frames 0 Split datasets into chunks of N frames (0 = no chunking)\nn_chunks 0 Alternative: number of chunks per dataset (0 = use chunk_frames)\nmaxn 100 Maximum neighbors for entropy calculation\nmax_iterations 10 Maximum iterations for :iterative mode\nconvergence_tol 0.001 Convergence tolerance in μm for :iterative mode\nwarm_start nothing Previous info.model for warm starting optimization\nverbose 0 Verbosity level: 0=quiet, 1=info, 2=debug\nauto_roi false Use dense ROI subset for faster estimation\nσ_loc 0.010 Typical localization precision (μm) for ROI sizing\nσ_target 0.001 Target drift precision (μm) for ROI sizing\nroi_safety_factor 4.0 Safety multiplier for required localizations\n\nExample\n\njulia> config = DriftConfig(quality=:iterative, degree=3);\n\njulia> config.quality\n:iterative\n\njulia> config.degree\n3\n\njulia> config.convergence_tol\n0.001\n\n\n\n\n\n","category":"type"},{"location":"configuration/#SMLMDriftCorrection.DriftInfo","page":"Configuration","title":"SMLMDriftCorrection.DriftInfo","text":"DriftInfo <: AbstractSMLMInfo\n\nMetadata from drift correction, returned as second element of tuple. Supports warm start via info.model.\n\nFields\n\nmodel::LegendrePolynomial: Fitted drift model (intra + inter)\nelapsed_s::Float64: Wall time in seconds\nbackend::Symbol: Computation backend (:cpu)\niterations::Int: Number of iterations completed (0 for :fft, 1 for :singlepass, N for :iterative)\nconverged::Bool: Whether convergence criterion was met (always true for :fft/:singlepass)\nentropy::Float64: Final entropy value after correction\nhistory::Vector{Float64}: Entropy per iteration (empty for :fft)\nroi_indices::Union{Nothing, Vector{Int}}: Indices used for ROI subsampling (nothing if not used)\n\nUsage\n\n(smld_corrected, info) = driftcorrect(smld)\ninfo.converged    # check convergence\ninfo.entropy      # final value\ninfo.elapsed_s    # timing\nplot(info.history)  # diagnostics\ninfo.roi_indices  # ROI used for estimation (nothing if auto_roi=false)\n\n# Warm start from previous result\n(smld2, info2) = driftcorrect(smld2; warm_start=info.model)\n\n\n\n\n\n","category":"type"},{"location":"configuration/#SMLMDriftCorrection.AlignConfig","page":"Configuration","title":"SMLMDriftCorrection.AlignConfig","text":"AlignConfig <: AbstractSMLMConfig\n\nConfiguration for rigid-shift alignment of independent SMLDs.\n\nFields\n\nField Default Description\nmethod :entropy Alignment method: :entropy (CC + entropy refinement) or :fft (CC only)\nmaxn 100 Maximum neighbors for entropy calculation\nhistbinsize 0.05 Histogram bin size (μm) for cross-correlation\nverbose 0 Verbosity level: 0=quiet, 1=info\n\n\n\n\n\n","category":"type"},{"location":"configuration/#SMLMDriftCorrection.AlignInfo","page":"Configuration","title":"SMLMDriftCorrection.AlignInfo","text":"AlignInfo <: AbstractSMLMInfo\n\nResult metadata from align_smld.\n\nFields\n\nshifts::Vector{Vector{Float64}}: Recovered shift for each SMLD (shifts[1] = zeros)\nelapsed_s::Float64: Wall time in seconds\nmethod::Symbol: Method used (:entropy or :fft)\nbackend::Symbol: Computation backend (:cpu)\n\n\n\n\n\n","category":"type"},{"location":"#SMLMDriftCorrection.jl","page":"Home","title":"SMLMDriftCorrection.jl","text":"Fiducial-free drift correction for Single Molecule Localization Microscopy (SMLM).","category":"section"},{"location":"#Overview","page":"Home","title":"Overview","text":"SMLMDriftCorrection.jl implements entropy-based drift correction using Legendre polynomial models. The package provides:\n\nIntra-dataset drift correction: Drift within each dataset (movie segment) modeled as a polynomial over time\nInter-dataset drift correction: Constant shifts between datasets to align them\nSMLD alignment (align_smld): Rigid-shift alignment of independent SMLD structures (e.g., multi-color channels)\n\nAll distance units are in micrometers (μm).","category":"section"},{"location":"#Installation","page":"Home","title":"Installation","text":"using Pkg\nPkg.add(\"SMLMDriftCorrection\")","category":"section"},{"location":"#Quick-Start","page":"Home","title":"Quick Start","text":"using SMLMSim\nusing SMLMDriftCorrection\nusing SMLMRender\nDC = SMLMDriftCorrection\nusing Random; Random.seed!(42)  # hide\n\n# Simulate blinking data (hexamers, 2 datasets)\nparams = StaticSMLMConfig(7.5, 0.13, 50, 2, 1000, 50.0, 2, [0.0, 1.0])\n(smld_noisy, _) = simulate(params;\n    pattern=Nmer2D(n=6, d=0.2),\n    molecule=GenericFluor(; photons=35000.0, k_on=0.25, k_off=50.0),\n    camera=IdealCamera(1:32, 1:32, 0.1)\n)\n\n# Create synthetic drift (~200nm diagonal) and apply it\ndrift_true = DC.LegendrePolynomial(smld_noisy; degree=2, initialize=\"zeros\")\nfor ds in 1:smld_noisy.n_datasets\n    drift_true.intra[ds].dm[1].coefficients .= [0.10, 0.03]   # x drift\n    drift_true.intra[ds].dm[2].coefficients .= [0.08, -0.02]   # y drift\nend\ndrift_true.inter[2].dm .= [0.05, -0.03]\nsmld_drifted = DC.applydrift(smld_noisy, drift_true)\n\n# Correct drift\n(smld_corrected, info) = driftcorrect(smld_drifted)\n\n# Results\nN = length(smld_noisy.emitters)\nrmsd = sqrt(sum(\n    ([e.x for e in smld_corrected.emitters] .- [e.x for e in smld_noisy.emitters]).^2 .+\n    ([e.y for e in smld_corrected.emitters] .- [e.y for e in smld_noisy.emitters]).^2\n) / N)\nprintln(\"Localizations: \", N)\nprintln(\"RMSD: \", round(rmsd * 1000, digits=1), \" nm\")\nprintln(\"Elapsed: \", round(info.elapsed_s, digits=1), \" s\")","category":"section"},{"location":"#Before-and-After","page":"Home","title":"Before and After","text":"Histogram renders colored by frame number show drift smearing (before) and recovery (after):\n\nDrifted — localizations smeared by ~200 nm of drift:\n\n(img_drifted, _) = render(smld_drifted, strategy=HistogramRender(), color_by=:frame, colormap=:turbo, zoom=10)\nsave_image(\"drifted.png\", img_drifted)\nnothing  # hide\n\n(Image: Drifted)\n\nCorrected — hexamer structure recovered (RMSD ~1 nm):\n\n(img_corrected, _) = render(smld_corrected, strategy=HistogramRender(), color_by=:frame, colormap=:turbo, zoom=10)\nsave_image(\"corrected.png\", img_corrected)\nnothing  # hide\n\n(Image: Corrected)","category":"section"},{"location":"#Usage-Examples","page":"Home","title":"Usage Examples","text":"","category":"section"},{"location":"#With-Simulated-Data","page":"Home","title":"With Simulated Data","text":"using SMLMSim\nusing SMLMDriftCorrection\nDC = SMLMDriftCorrection\n\n# Simulate data\nparams = StaticSMLMConfig(10.0, 0.13, 30, 3, 1000, 50.0, 2, [0.0, 1.0])\n(smld_noisy, _) = simulate(params;\n    pattern=Nmer2D(n=6, d=0.2),\n    molecule=GenericFluor(; photons=5000.0, k_on=0.02, k_off=50.0),\n    camera=IdealCamera(1:64, 1:64, 0.1)\n)\n\n# Create and apply synthetic drift\ndrift_true = DC.LegendrePolynomial(smld_noisy; degree=2, initialize=\"random\", rscale=0.1)\nsmld_drifted = DC.applydrift(smld_noisy, drift_true)\n\n# Correct drift\nconfig = DriftConfig(verbose=1)\n(smld_corrected, info) = driftcorrect(smld_drifted, config)","category":"section"},{"location":"#With-SMITE-Data","page":"Home","title":"With SMITE Data","text":"using SMLMData\nusing SMLMDriftCorrection\n\nsmd = SmiteSMD(path, file)   # *_Results.mat file\nsmld = load_smite_2d(smd)\n(smld_corrected, info) = driftcorrect(smld, DriftConfig(verbose=1))","category":"section"},{"location":"#Filtering-to-ROI","page":"Home","title":"Filtering to ROI","text":"x = [e.x for e in smld.emitters]\ny = [e.y for e in smld.emitters]\nmask = (x .> 64.0) .& (x .< 128.0) .& (y .> 64.0) .& (y .< 128.0)\nsmld_roi = filter_emitters(smld, mask)\n\n(smld_corrected, info) = driftcorrect(smld_roi, DriftConfig())","category":"section"},{"location":"#Continuous-Acquisition-Mode","page":"Home","title":"Continuous Acquisition Mode","text":"For data where drift accumulates across files (one long acquisition split into multiple datasets):\n\n# Continuous mode - drift chains across datasets\nconfig = DriftConfig(dataset_mode=:continuous)\n(smld_corrected, info) = driftcorrect(smld, config)\n\n# With chunking for finer-grained correction\nconfig = DriftConfig(dataset_mode=:continuous, chunk_frames=4000)\n(smld_corrected, info) = driftcorrect(smld, config)","category":"section"},{"location":"#Aligning-Independent-SMLDs","page":"Home","title":"Aligning Independent SMLDs","text":"For aligning separate acquisitions or multi-color channels:\n\nusing SMLMDriftCorrection\n\n(aligned, info) = align_smld([smld_ch1, smld_ch2]; method=:entropy)\ninfo.shifts  # [zeros(2), [dx, dy]]","category":"section"},{"location":"#Warm-Start-/-Continuation","page":"Home","title":"Warm Start / Continuation","text":"# Warm start from previous model\nconfig1 = DriftConfig(degree=2)\n(smld1, info1) = driftcorrect(smld1, config1)\n\nconfig2 = DriftConfig(warm_start=info1.model)\n(smld2, info2) = driftcorrect(smld2, config2)\n\n# Continue iterating from previous result\n(smld3, info3) = driftcorrect(smld1, info1; max_iterations=5)","category":"section"},{"location":"#Dataset-Modes","page":"Home","title":"Dataset Modes","text":"Both modes use the same entropy-based alignment algorithm. The difference is semantic:\n\n:registered (default): Datasets are independent acquisitions. Use default trajectory plotting.\n:continuous: One long acquisition split into multiple files. Use drift_trajectory(info.model; cumulative=true) for plotting accumulated drift.","category":"section"},{"location":"#Algorithm","page":"Home","title":"Algorithm","text":"The algorithm uses entropy minimization (Cnossen et al., 2021) with Legendre polynomial basis functions:\n\nIntra-dataset: For each dataset, fit a Legendre polynomial (degree 2 by default) to model drift over time. Uses KL divergence-based entropy as cost function with adaptive KDTree neighbor rebuilding. Threaded across datasets.\nInter-dataset: Align datasets using constant shifts optimized via merged-cloud entropy minimization. First pass aligns all to dataset 1 (threaded), then sequential refinement against all earlier datasets.\nIterative (:iterative quality only): Repeat intra↔inter until inter-shift changes converge below tolerance.\n\nThe Legendre polynomial basis provides better optimization conditioning than standard polynomials because the basis functions are orthogonal over the normalized time domain [-1, 1].\n\ntip: Threading\nIntra-dataset correction and the first inter-dataset pass are parallelized with Threads.@threads. Start Julia with multiple threads (e.g., julia -t auto) for best performance on multi-dataset data.","category":"section"},{"location":"#References","page":"Home","title":"References","text":"Cnossen J, et al. \"Drift correction in localization microscopy using entropy minimization\", Optics Express 29(18), 2021. DOI: 10.1364/OE.426620\nWester MJ, et al. \"Robust, fiducial-free drift correction for super-resolution imaging\", Scientific Reports 11, 2021. DOI: 10.1038/s41598-021-02850-7","category":"section"},{"location":"#Documentation","page":"Home","title":"Documentation","text":"Configuration - Full description of DriftConfig input and DriftInfo output\nTheory & Workflow - Algorithm background, dataset modes, and quality tiers\nAPI Reference - Complete API documentation","category":"section"},{"location":"theory_workflow/#Theory-and-Workflow","page":"Theory & Workflow","title":"Theory and Workflow","text":"","category":"section"},{"location":"theory_workflow/#Background","page":"Theory & Workflow","title":"Background","text":"Sample drift is a fundamental challenge in single molecule localization microscopy (SMLM). During acquisition, thermal fluctuations, mechanical settling, and other perturbations cause the sample to move relative to the optical system. Because super-resolution images are constructed from thousands of individual localizations accumulated over minutes to hours, even nanometer-scale drift degrades the final resolution.\n\nThis package implements a fiducial-free drift correction algorithm – no reference markers are needed. Instead, the algorithm exploits the statistical redundancy inherent in SMLM data: the same fluorophores blink multiple times across different frames, creating repeated observations of fixed structures. By finding the drift trajectory that produces the tightest spatial clustering of these repeated observations, the drift can be estimated and corrected.","category":"section"},{"location":"theory_workflow/#Drift-Model","page":"Theory & Workflow","title":"Drift Model","text":"","category":"section"},{"location":"theory_workflow/#Algorithmic-Framework","page":"Theory & Workflow","title":"Algorithmic Framework","text":"This package is based on Wester et al. (2021), which introduced a two-phase parametric approach to fiducial-free drift correction:\n\nIntra-dataset correction: Drift within each acquisition segment is modeled as a polynomial function of frame number (a proxy for time), with no constant term since global offsets are handled separately.\nInter-dataset correction: Constant lateral shifts between datasets account for registration errors or repositioning between acquisition segments.\n\nThis decomposition separates two physically distinct drift sources: continuous thermal/mechanical drift during acquisition (intra) and discrete repositioning errors between acquisitions (inter).\n\nThe current implementation makes two key updates to the original Wester et al. algorithm:","category":"section"},{"location":"theory_workflow/#Update-1:-Entropy-Cost-Function","page":"Theory & Workflow","title":"Update 1: Entropy Cost Function","text":"Wester et al. used a saturated nearest-neighbor distance cost function:\n\nC(theta) = sum_i=1^N min(d_i ell)\n\nwhere d_i is the nearest-neighbor distance for localization i after drift correction and ell is a saturation threshold. The saturation prevents distant pairs (from different emitters) from dominating the cost. While effective, this cost function does not account for the varying localization precisions (sigma) of individual localizations.\n\nWe adopted the entropy minimization cost function of Cnossen et al. (2021), which models the SMLM reconstruction as a Gaussian mixture:\n\np(mathbfr) = frac1N sum_i=1^N mathcalN(mathbfr boldsymbolmu_i - mathbfd(t_i) boldsymbolSigma_i)\n\nwhere boldsymbolmu_i is the measured position, boldsymbolSigma_i is the diagonal covariance from localization uncertainty, and mathbfd(t_i) is the drift at frame t_i.\n\nSince the entropy of a Gaussian mixture has no closed form, we minimize a variational upper bound:\n\nH_textub(mathbfD) = frac1Nsum_i H_i - frac1Nsum_i logBigl(frac1Nsum_j neq i e^-D_textKL(p_i  p_j)Bigr)\n\nThe first term H_i is the entropy of each individual Gaussian component (determined only by localization uncertainties, constant during optimization). The second term depends on pairwise KL divergences between Gaussian localizations:\n\nD_textKL(i j) = frac12sum_k=1^K leftlogfracsigma_jk^2sigma_ik^2 + fracsigma_ik^2sigma_jk^2 + frac(mu_ik - mu_jk)^2sigma_jk^2 - 1right\n\nThe drift parameters enter through the corrected positions mu_ik. When drift is correctly removed, localizations from the same emitter cluster tightly, the KL divergences shrink, and the entropy decreases.\n\nFor computational efficiency, the pairwise sum is truncated to the k nearest neighbors of each localization (default k = 200), computed via KDTree. The KDTree is rebuilt adaptively – only when the drift estimate changes by more than 100 nm – avoiding O(N log N) rebuilds on every optimizer iteration.","category":"section"},{"location":"theory_workflow/#Update-2:-Legendre-Polynomial-Basis","page":"Theory & Workflow","title":"Update 2: Legendre Polynomial Basis","text":"Wester et al. used standard monomials (f f^2 ldots) for the drift polynomial. We use Legendre polynomials (P_1(t) P_2(t) ldots) evaluated on normalized time t in -1 1:\n\nt = frac2(f - 1)n_textframes - 1 - 1\n\nThe orthogonality of the Legendre basis provides better optimization conditioning, especially for higher polynomial degrees. Each coefficient captures independent variation, preventing the numerical ill-conditioning that arises with standard polynomial bases at high degree.\n\nAs in Wester et al., the constant term (P_0) is excluded from the intra-dataset model. Global offsets are handled by the inter-dataset shifts.","category":"section"},{"location":"theory_workflow/#Dataset-Modes","page":"Theory & Workflow","title":"Dataset Modes","text":"The package supports three acquisition scenarios through the dataset_mode parameter and chunking options:","category":"section"},{"location":"theory_workflow/#Continuous-(Single-Polynomial)","page":"Theory & Workflow","title":"Continuous (Single Polynomial)","text":"For short acquisitions (fewer than ~4000 frames), drift is modeled as a single polynomial over the entire dataset:\n\nconfig = DriftConfig(dataset_mode=:continuous, degree=3)\n(smld_corrected, info) = driftcorrect(smld, config)\n\nThis fits one n-th order Legendre polynomial per spatial dimension to capture the smooth, continuous drift trajectory. Best when the drift is well-described by a low-order polynomial over the full acquisition.","category":"section"},{"location":"theory_workflow/#Continuous-(Piecewise-Chunked)","page":"Theory & Workflow","title":"Continuous (Piecewise Chunked)","text":"For long acquisitions, a single polynomial may not capture complex drift patterns or may become numerically unstable at high degree. The data is arbitrarily split into temporal chunks, each fit with its own polynomial:\n\nconfig = DriftConfig(dataset_mode=:continuous, chunk_frames=4000)\n(smld_corrected, info) = driftcorrect(smld, config)\n\nEach chunk is treated as a separate \"dataset\" internally. Warm-starting ensures continuity: each chunk's polynomial is initialized from the endpoint of the previous chunk's fit. The inter-dataset shifts chain the chunks together, with regularization from boundary gap estimates to prevent discontinuities. This piecewise approach provides the flexibility of high-order modeling without requiring a single high-degree polynomial over the full acquisition.","category":"section"},{"location":"theory_workflow/#Registered","page":"Theory & Workflow","title":"Registered","text":"For instruments that periodically register the sample to a reference position between acquisition segments – such as the Sequential Super-resolution Microscope (SeqSRM) described in Schodt et al. (2023) – the datasets are independent acquisitions with bounded drift:\n\nconfig = DriftConfig(dataset_mode=:registered)\n(smld_corrected, info) = driftcorrect(smld, config)\n\nBetween acquisition segments, the microscope acquires a brightfield z-stack, computes 3D cross-correlation against a reference, and iteratively moves the stage to realign the sample. This bounds the inter-dataset drift to the registration precision (typically 5-10 nm lateral). However, residual registration errors and intra-segment drift still require computational correction.\n\nIn registered mode, datasets are spatially overlapping images of the same field of view. The inter-dataset alignment uses merged-cloud entropy: the shifted dataset's localizations are combined with reference dataset localizations into a single point cloud, and the entropy of the combined cloud is minimized. This finds the constant shift that produces the tightest merged distribution.","category":"section"},{"location":"theory_workflow/#Quality-Tiers","page":"Theory & Workflow","title":"Quality Tiers","text":"The package provides three quality tiers that trade speed for accuracy. All three share the same drift model (Legendre polynomials + inter-shifts); they differ in how the model parameters are estimated.\n\ntip: Multi-threading\nIntra-dataset correction is parallelized with Threads.@threads (each dataset is independent). The first inter-dataset pass (all vs dataset 1) is also threaded using a precomputed snapshot of corrected coordinates. Start Julia with multiple threads for best performance:julia -t auto        # use all available cores\njulia -t 8           # use 8 threads","category":"section"},{"location":"theory_workflow/#FFT-(:fft)","page":"Theory & Workflow","title":"FFT (:fft)","text":"The fastest tier. Uses cross-correlation of histogram images to estimate inter-dataset shifts. No intra-dataset polynomial fitting is performed.\n\nProcedure:\n\nBuild 2D (or 3D) histogram images from each dataset's localizations\nPass 1: Compute cross-correlation of each dataset against dataset 1 via FFT; extract shift from the correlation peak with sub-pixel Gaussian refinement\nPass 2: Refine each dataset's shift against a merged histogram of all other (shifted) datasets\nPass 3: Detect outlier shifts (>5 MAD from median) and re-align them using a Gaussian-damped cross-correlation prior\n\nBest for: quick previews, very large datasets, or as initialization for entropy-based methods.","category":"section"},{"location":"theory_workflow/#Singlepass-(:singlepass)","page":"Theory & Workflow","title":"Singlepass (:singlepass)","text":"The default tier. Performs one pass of entropy-based intra-dataset correction followed by inter-dataset alignment.\n\nProcedure:\n\nIntra-dataset correction (threaded across datasets):\nInitialize polynomial coefficients with small random values\nMinimize entropy upper bound using Nelder-Mead optimization (10,000 iteration limit)\nAdaptive KDTree rebuilding avoids unnecessary recomputation\nInter-dataset alignment, Pass 1 (threaded, all vs dataset 1):\nFor each dataset n  1, apply intra-correction to dataset n and full correction to dataset 1\nUse cross-correlation for initial shift estimate\nRefine via BFGS optimization of merged-cloud entropy\nInter-dataset alignment, Pass 2 (sequential, each vs all earlier):\nFor each dataset n, re-optimize the shift against all datasets 1 ldots n-1\nThis incorporates information from the intermediate datasets\nApply corrections to produce the final SMLD\n\nFor continuous mode, inter-shifts are warm-started from polynomial endpoint chaining and regularized using boundary gap estimates.","category":"section"},{"location":"theory_workflow/#Iterative-(:iterative)","page":"Theory & Workflow","title":"Iterative (:iterative)","text":"The most accurate tier. Iterates between intra and inter correction until convergence.\n\nProcedure:\n\nRun the full singlepass procedure as initialization\nIterate until convergence (default: max 10 iterations, tolerance 1 nm): a. Re-run intra-dataset correction with inter-shifts applied (shifted coordinates), threaded across datasets b. Re-run inter-dataset alignment using Jacobi-style updates (snapshot corrected data, then thread all-vs-others) c. Check convergence: maximum change in any inter-shift component < convergence_tol\nTrack entropy history for diagnostics (info.history)\n\nThe iteration resolves the coupling between intra and inter corrections: the optimal polynomial depends on the inter-shifts, and vice versa. For data with significant inter-dataset drift, iterative mode can improve accuracy substantially over singlepass.","category":"section"},{"location":"theory_workflow/#References","page":"Theory & Workflow","title":"References","text":"Cnossen J, Cui TJ, Joo C, Smith C. \"Drift correction in localization microscopy using entropy minimization.\" Optics Express 29(18):27961-27974, 2021. DOI: 10.1364/OE.426620\nWester MJ, Schodt DJ, Mazloom-Farsibaf H, Fazel M, Pallikkuth S, Lidke KA. \"Robust, fiducial-free drift correction for super-resolution imaging.\" Scientific Reports 11:23672, 2021. DOI: 10.1038/s41598-021-02850-7\nSchodt DJ, Farzam F, Liu S, Lidke KA. \"Automated multi-target super-resolution microscopy with trust regions.\" Biomedical Optics Express 14(1):429-440, 2023. DOI: 10.1364/BOE.477501","category":"section"}]
}
